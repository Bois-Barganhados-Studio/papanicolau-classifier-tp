{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install Image\n",
    "! pip install matplotlib\n",
    "! pip install numpy\n",
    "! pip install scikit-image\n",
    "! pip install scikit-learn\n",
    "! pip install opencv-python\n",
    "! pip install seaborn\n",
    "! pip install torch torchvision efficientnet_pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables - Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'classifications.csv'\n",
    "IMAGE_SET_PATH = 'dataset'\n",
    "CLASSES_PATH = 'classes'\n",
    "MODELS_PATH = 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_existing_images(data):\n",
    "    existing_imgs = []\n",
    "    missing_img = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        \n",
    "        image_path = os.path.join(IMAGE_SET_PATH, row['image_filename'])\n",
    "        if os.path.isfile(image_path):\n",
    "            existing_imgs.append(index)\n",
    "        else:\n",
    "            missing_img.append(row['image_filename'])\n",
    "\n",
    "    filtered_data = data.loc[existing_imgs]\n",
    "    filtered_data['bethesda_system'] = filtered_data['bethesda_system'].replace('Negative for intraepithelial lesion', 'Negative_for_intraepithelial_lesion')\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping and Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_dir (classes):\n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(CLASSES_PATH, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_box (x, y, width, height, crop_size = 100):\n",
    "    half_crop = crop_size // 2\n",
    "    left = max(0, x - half_crop)\n",
    "    upper = max(0, y - half_crop)\n",
    "    right = min(width, x + half_crop)\n",
    "    lower = min(height, y + half_crop)\n",
    "\n",
    "    if right - left < crop_size:\n",
    "        if left == 0:\n",
    "            right = left + crop_size\n",
    "        else:\n",
    "            left = right - crop_size\n",
    "    if lower - upper < crop_size:\n",
    "        if upper == 0:\n",
    "            lower = upper + crop_size\n",
    "        else:\n",
    "            upper = lower - crop_size\n",
    "\n",
    "    return (left, upper, right, lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grayscale_histogram(img, bins = 16):\n",
    "    grayscale_image = img.convert(\"L\")\n",
    "    histogram, bin_edges = np.histogram(grayscale_image, bins=bins, range=(0,255))\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hsv_histogram(img, h_bins=16, v_bins=8):\n",
    "    hsv_img = img.convert(\"HSV\")\n",
    "    h, s, v = hsv_img.split()\n",
    "    h = np.array(h) // (256 // h_bins)\n",
    "    v = np.array(v) // (256 // v_bins)\n",
    "    histogram, _, _ = np.histogram2d(h.flatten(), v.flatten(), bins=[h_bins, v_bins], range=[[0, h_bins], [0, v_bins]])\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_image(image, levels = 16):\n",
    "    grayscale_image = image.convert(\"L\")\n",
    "    quantized_image = np.array(grayscale_image) // (256 // levels)\n",
    "    return quantized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cooccurrence_matrices(q_img, distances=[1, 2, 4, 8, 16, 32], angles=[0]):\n",
    "    cooccurrence_matrices = graycomatrix(q_img, distances, angles, levels=16, symmetric=True, normed=True)\n",
    "    return cooccurrence_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_glcm(q_img, dists=[1, 2 ,4, 8, 16, 32], angles=[0]):\n",
    "    glcm = graycomatrix(q_img, distances=dists, angles=angles, levels=16, symmetric=True, normed=True)\n",
    "    return glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haralick_features(glcm):\n",
    "    contrast = graycoprops(glcm, 'contrast').flatten()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    \n",
    "    glcm_sum = glcm.sum(axis=(0, 1))\n",
    "    norm_glcm = glcm / glcm_sum\n",
    "    entropy = -np.sum(norm_glcm * np.log(norm_glcm + 1e-10), axis=(0, 1)).flatten()\n",
    "    \n",
    "    features = {\n",
    "        'contrast': contrast,\n",
    "        'homogeneity': homogeneity,\n",
    "        'entropy': entropy\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(classes, image_size=(100, 100)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(CLASSES_PATH, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.png'):\n",
    "                img_path = os.path.join(class_dir, filename)\n",
    "                img = Image.open(img_path).resize(image_size)\n",
    "                img_array = np.array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(class_name)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNet Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_train_test_imgs (train_df, test_df, class_column_name, data_dir):\n",
    "\n",
    "    train_dir_path = 'train'\n",
    "    test_dir_path = 'test'\n",
    "\n",
    "    train_dir_path = os.path.join(data_dir, train_dir_path)\n",
    "    test_dir_path = os.path.join(data_dir, test_dir_path)\n",
    "\n",
    "    for index, row in train_df.iterrows():\n",
    "            cell_id = row['cell_id']\n",
    "            train_class_dir = os.path.join(train_dir_path, row[class_column_name])\n",
    "            if not os.path.exists(train_class_dir):\n",
    "                os.makedirs(train_class_dir)\n",
    "            src_path = row['image_path']\n",
    "            dst_path = os.path.join(train_class_dir, f'{cell_id}.png')\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "            cell_id = row['cell_id']\n",
    "            test_class_dir = os.path.join(test_dir_path, row[class_column_name])\n",
    "            if not os.path.exists(test_class_dir):\n",
    "                os.makedirs(test_class_dir)\n",
    "            src_path = row['image_path']\n",
    "            dst_path = os.path.join(test_class_dir, f'{cell_id}.png')\n",
    "            shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tranforms():\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(256),  # Redimensiona para 256x256 antes do recorte aleatório\n",
    "            transforms.RandomResizedCrop(224),  # Recorta aleatoriamente para 224x224\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(256),  # Redimensiona para 256x256 antes do recorte central\n",
    "            transforms.CenterCrop(224),  # Recorta centralmente para 224x224\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, device, dataset_sizes, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Cada época possui uma fase de treino e uma de validação\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Configura o modelo para treinamento\n",
    "            else:\n",
    "                model.eval()   # Configura o modelo para avaliação\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Itera sobre os dados\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zera os gradientes dos parâmetros\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history se apenas na fase de treino\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + otimiza apenas na fase de treino\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Estatísticas\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Profunda cópia do modelo\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Carrega os melhores pesos do modelo\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloaders, device):\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODELS_PATH):  \n",
    "    os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "brute_data = pd.read_csv(CSV_PATH)\n",
    "table_data = filter_existing_images(brute_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping and Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_class_dir(table_data['bethesda_system'].unique())\n",
    "\n",
    "for index, row in table_data.iterrows():\n",
    "    image_path = os.path.join(IMAGE_SET_PATH, row['image_filename'])\n",
    "    x, y = int(row['nucleus_x']), int(row['nucleus_y'])\n",
    "    class_name = row['bethesda_system']\n",
    "    cell_id = row['cell_id']\n",
    "\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        crop_box = get_crop_box(x, y, width, height)\n",
    "        cropped_img = img.crop(crop_box)\n",
    "\n",
    "        output_path = os.path.join(CLASSES_PATH, class_name, f'{cell_id}.png')\n",
    "        cropped_img.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "\n",
    "for index, row in table_data.iterrows():\n",
    "    cell_id = row['cell_id']\n",
    "    img_path = os.path.join(CLASSES_PATH, row['bethesda_system'], f\"{row['cell_id']}.png\")\n",
    "    img_class = row['bethesda_system']\n",
    "\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    if image is not None:\n",
    "        q_img = quantize_image(image)\n",
    "        glcm = compute_glcm(q_img)\n",
    "        haralick_features = compute_haralick_features(glcm)\n",
    "\n",
    "        img_data.append ({\n",
    "            'cell_id': cell_id,\n",
    "            'image_path': img_path,\n",
    "            'contrast_1': haralick_features['contrast'][0],\n",
    "            'contrast_2': haralick_features['contrast'][1],\n",
    "            'contrast_4': haralick_features['contrast'][2],\n",
    "            'contrast_8': haralick_features['contrast'][3],\n",
    "            'contrast_16': haralick_features['contrast'][4],\n",
    "            'contrast_32': haralick_features['contrast'][5],\n",
    "            'homogeneity_1': haralick_features['homogeneity'][0],\n",
    "            'homogeneity_2': haralick_features['homogeneity'][1],\n",
    "            'homogeneity_4': haralick_features['homogeneity'][2],\n",
    "            'homogeneity_8': haralick_features['homogeneity'][3],\n",
    "            'homogeneity_16': haralick_features['homogeneity'][4],\n",
    "            'homogeneity_32': haralick_features['homogeneity'][5],\n",
    "            'entropy_1': haralick_features['entropy'][0],\n",
    "            'entropy_2': haralick_features['entropy'][1],\n",
    "            'entropy_4': haralick_features['entropy'][2],\n",
    "            'entropy_8': haralick_features['entropy'][3],\n",
    "            'entropy_16': haralick_features['entropy'][4],\n",
    "            'entropy_32': haralick_features['entropy'][5],\n",
    "            'img_class': img_class\n",
    "        })\n",
    "        \n",
    "dataset = pd.DataFrame(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.drop(columns=['cell_id', 'image_path', 'img_class'])\n",
    "labels = dataset['img_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels = np.array(['Negative' if label == 'Negative_for_intraepithelial_lesion' else 'Positive' for label in labels])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, binary_labels, test_size=0.2, stratify=binary_labels, random_state=49)\n",
    "\n",
    "# Step 1: Undersample the predominant class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=49, k_neighbors=5, sampling_strategy='not majority')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch for Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 'scale'],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "svc = SVC(class_weight='balanced', random_state=49)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Evaluate the Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_svm_classifier = SVC(**best_params, class_weight='balanced', random_state=49)\n",
    "binary_svm_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = binary_svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Binary SVC Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_matrix, classes=['Negative', 'Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the Binary SVM Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'binary_svm_classifier.pkl'\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, model_filename)\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    \n",
    "    pickle.dump(binary_svm_classifier, file)\n",
    "\n",
    "# Load the model\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(\"Loaded Model Accuracy:\", accuracy_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=49)\n",
    "\n",
    "# Step 1: Undersample the predominant class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=49, k_neighbors=5, sampling_strategy='not majority')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomizedSearch for Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'C': loguniform(1e-3, 1e3),\n",
    "    'gamma': loguniform(1e-6, 1e-1),\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "svc = SVC(class_weight='balanced', random_state=49)\n",
    "\n",
    "# Instantiate the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=svc, param_distributions=param_distributions, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring='accuracy', random_state=49)\n",
    "\n",
    "# Time the randomized search\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Evaluate the Multiclass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_svm_classifier = SVC(**best_params, class_weight='balanced', random_state=49)\n",
    "multiclass_svm_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = multiclass_svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Multi-Class SVM Accuracy:\", accuracy)\n",
    "print(\"Multi-Class SVM Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_matrix, classes=['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative_for_intraepithelial_lesion', 'SCC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the Multiclass SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'multiclass_svm_classifier.pkl'\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, model_filename)\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(multiclass_svm_classifier, file)\n",
    "\n",
    "# Load the model\n",
    "with open(model_filename, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(\"Loaded Model Accuracy:\", accuracy_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary EfficientNet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Treat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "class_name = 'binary_class'\n",
    "bin_data_dir = 'effnet_data_binary'\n",
    "\n",
    "df[class_name] = df['img_class'].apply(lambda x: 'Negative' if x == 'Negative_for_intraepithelial_lesion' else 'Positive')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[class_name], random_state=49)\n",
    "\n",
    "copy_train_test_imgs(train_df,test_df, class_name, bin_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = get_data_tranforms()\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(bin_data_dir, x),data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([label for _, label in image_datasets['train'].imgs])\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Criação de um WeightedRandomSampler\n",
    "class_sample_counts = np.array([len(np.where(train_labels == t)[0]) for t in np.unique(train_labels)])\n",
    "weights = 1. / class_sample_counts\n",
    "samples_weights = weights[train_labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "\n",
    "# Atualizando o DataLoader de treino para usar o WeightedRandomSampler\n",
    "train_loader = DataLoader(image_datasets['train'], batch_size=batch_size, sampler=sampler, num_workers=4)\n",
    "test_loader = dataloaders['test']\n",
    "dataloaders['train'] = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary_efficientNet = train_model(model, dataloaders, criterion, optimizer, device, dataset_sizes, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary_efficientNet = model_binary_efficientNet.to(torch.device('cuda:0'))\n",
    "\n",
    "# Avalia o modelo no conjunto de teste\n",
    "labels, preds = evaluate_model(model_binary_efficientNet, dataloaders, device)\n",
    "\n",
    "# Calcula acurácia, precisão, recall e F1-score\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Imprime as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Precisão: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Converte a matriz de confusão para um DataFrame para melhor visualização\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação detalhado\n",
    "report = classification_report(labels, preds, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "path = os.path.join(MODELS_PATH, 'efficientNet_binary.pth')\n",
    "torch.save(model_binary_efficientNet.to(torch.device('cpu')), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass EfficientNet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Treat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "class_name = 'img_class'\n",
    "multi_data_dir = 'effnet_data_multiclass'\n",
    "\n",
    "df = df[df[class_name] != 'Negative_for_intraepithelial_lesion']\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[class_name], random_state=49)\n",
    "\n",
    "copy_train_test_imgs(train_df,test_df, class_name, multi_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = get_data_tranforms()\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(multi_data_dir, x),data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([label for _, label in image_datasets['train'].imgs])\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Criação de um WeightedRandomSampler\n",
    "class_sample_counts = np.array([len(np.where(train_labels == t)[0]) for t in np.unique(train_labels)])\n",
    "weights = 1. / class_sample_counts\n",
    "samples_weights = weights[train_labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "\n",
    "# Atualizando o DataLoader de treino para usar o WeightedRandomSampler\n",
    "train_loader = DataLoader(image_datasets['train'], batch_size=batch_size, sampler=sampler, num_workers=4)\n",
    "test_loader = dataloaders['test']\n",
    "dataloaders['train'] = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiclass_efficientNet = train_model(model, dataloaders, criterion, optimizer, device,  dataset_sizes, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia o modelo no conjunto de teste\n",
    "model_multiclass_efficientNet = model_multiclass_efficientNet.to(torch.device('cuda:0'))\n",
    "labels, preds = evaluate_model(model_multiclass_efficientNet, dataloaders, device)\n",
    "\n",
    "# Calcula acurácia, precisão, recall e F1-score\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Imprime as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Precisão: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Converte a matriz de confusão para um DataFrame para melhor visualização\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação detalhado\n",
    "report = classification_report(labels, preds, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "path = os.path.join(MODELS_PATH, 'efficientNet_muticlass.pth')\n",
    "torch.save(model_multiclass_efficientNet.to(torch.device('cpu')), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
