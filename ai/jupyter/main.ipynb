{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install Image\n",
    "! pip install matplotlib\n",
    "! pip install numpy\n",
    "! pip install scikit-image\n",
    "! pip install scikit-learn\n",
    "! pip install opencv-python\n",
    "! pip install seaborn\n",
    "! pip install torch torchvision efficientnet_pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables - Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'classifications.csv'\n",
    "IMAGE_SET_PATH = 'dataset'\n",
    "CLASSES_PATH = 'classes'\n",
    "MODELS_PATH = 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_existing_images(data):\n",
    "    existing_imgs = []\n",
    "    missing_img = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        \n",
    "        image_path = os.path.join(IMAGE_SET_PATH, row['image_filename'])\n",
    "        if os.path.isfile(image_path):\n",
    "            existing_imgs.append(index)\n",
    "        else:\n",
    "            missing_img.append(row['image_filename'])\n",
    "\n",
    "    filtered_data = data.loc[existing_imgs]\n",
    "    filtered_data['bethesda_system'] = filtered_data['bethesda_system'].replace('Negative for intraepithelial lesion', 'Negative_for_intraepithelial_lesion')\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping and Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_dir (classes):\n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(CLASSES_PATH, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_box (x, y, width, height, crop_size = 100):\n",
    "    half_crop = crop_size // 2\n",
    "    left = max(0, x - half_crop)\n",
    "    upper = max(0, y - half_crop)\n",
    "    right = min(width, x + half_crop)\n",
    "    lower = min(height, y + half_crop)\n",
    "\n",
    "    if right - left < crop_size:\n",
    "        if left == 0:\n",
    "            right = left + crop_size\n",
    "        else:\n",
    "            left = right - crop_size\n",
    "    if lower - upper < crop_size:\n",
    "        if upper == 0:\n",
    "            lower = upper + crop_size\n",
    "        else:\n",
    "            upper = lower - crop_size\n",
    "\n",
    "    return (left, upper, right, lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grayscale_histogram(img, bins = 16):\n",
    "    grayscale_image = img.convert(\"L\")\n",
    "    histogram, bin_edges = np.histogram(grayscale_image, bins=bins, range=(0,255))\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hsv_histogram(img, h_bins=16, v_bins=8):\n",
    "    hsv_img = img.convert(\"HSV\")\n",
    "    h, s, v = hsv_img.split()\n",
    "    h = np.array(h) // (256 // h_bins)\n",
    "    v = np.array(v) // (256 // v_bins)\n",
    "    histogram, _, _ = np.histogram2d(h.flatten(), v.flatten(), bins=[h_bins, v_bins], range=[[0, h_bins], [0, v_bins]])\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_image(image, levels = 16):\n",
    "    grayscale_image = image.convert(\"L\")\n",
    "    quantized_image = np.array(grayscale_image) // (256 // levels)\n",
    "    return quantized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cooccurrence_matrices(q_img, distances=[1, 2, 4, 8, 16, 32], angles=[0]):\n",
    "    cooccurrence_matrices = graycomatrix(q_img, distances, angles, levels=16, symmetric=True, normed=True)\n",
    "    return cooccurrence_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_glcm(q_img, dists=[1, 2 ,4, 8, 16, 32], angles=[0]):\n",
    "    glcm = graycomatrix(q_img, distances=dists, angles=angles, levels=16, symmetric=True, normed=True)\n",
    "    return glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haralick_features(glcm):\n",
    "    contrast = graycoprops(glcm, 'contrast').flatten()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    \n",
    "    glcm_sum = glcm.sum(axis=(0, 1))\n",
    "    norm_glcm = glcm / glcm_sum\n",
    "    entropy = -np.sum(norm_glcm * np.log(norm_glcm + 1e-10), axis=(0, 1)).flatten()\n",
    "    \n",
    "    features = {\n",
    "        'contrast': contrast,\n",
    "        'homogeneity': homogeneity,\n",
    "        'entropy': entropy\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(classes, image_size=(100, 100)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(CLASSES_PATH, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.png'):\n",
    "                img_path = os.path.join(class_dir, filename)\n",
    "                img = Image.open(img_path).resize(image_size)\n",
    "                img_array = np.array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(class_name)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNet Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_train_test_imgs (train_df, test_df, class_column_name, data_dir):\n",
    "\n",
    "    train_dir_path = 'train'\n",
    "    test_dir_path = 'test'\n",
    "\n",
    "    train_dir_path = os.path.join(data_dir, train_dir_path)\n",
    "    test_dir_path = os.path.join(data_dir, test_dir_path)\n",
    "\n",
    "    for index, row in train_df.iterrows():\n",
    "            cell_id = row['cell_id']\n",
    "            train_class_dir = os.path.join(train_dir_path, row[class_column_name])\n",
    "            if not os.path.exists(train_class_dir):\n",
    "                os.makedirs(train_class_dir)\n",
    "            src_path = row['image_path']\n",
    "            dst_path = os.path.join(train_class_dir, f'{cell_id}.png')\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "            cell_id = row['cell_id']\n",
    "            test_class_dir = os.path.join(test_dir_path, row[class_column_name])\n",
    "            if not os.path.exists(test_class_dir):\n",
    "                os.makedirs(test_class_dir)\n",
    "            src_path = row['image_path']\n",
    "            dst_path = os.path.join(test_class_dir, f'{cell_id}.png')\n",
    "            shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tranforms():\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(256),  # Redimensiona para 256x256 antes do recorte aleatório\n",
    "            transforms.RandomResizedCrop(224),  # Recorta aleatoriamente para 224x224\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(256),  # Redimensiona para 256x256 antes do recorte central\n",
    "            transforms.CenterCrop(224),  # Recorta centralmente para 224x224\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, device, dataset_sizes, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Cada época possui uma fase de treino e uma de validação\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Configura o modelo para treinamento\n",
    "            else:\n",
    "                model.eval()   # Configura o modelo para avaliação\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Itera sobre os dados\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zera os gradientes dos parâmetros\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history se apenas na fase de treino\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + otimiza apenas na fase de treino\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Estatísticas\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Profunda cópia do modelo\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Carrega os melhores pesos do modelo\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloaders, device):\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_data = pd.read_csv(CSV_PATH)\n",
    "table_data = filter_existing_images(brute_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping and Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_class_dir(table_data['bethesda_system'].unique())\n",
    "\n",
    "for index, row in table_data.iterrows():\n",
    "    image_path = os.path.join(IMAGE_SET_PATH, row['image_filename'])\n",
    "    x, y = int(row['nucleus_x']), int(row['nucleus_y'])\n",
    "    class_name = row['bethesda_system']\n",
    "    cell_id = row['cell_id']\n",
    "\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        crop_box = get_crop_box(x, y, width, height)\n",
    "        cropped_img = img.crop(crop_box)\n",
    "\n",
    "        output_path = os.path.join(CLASSES_PATH, class_name, f'{cell_id}.png')\n",
    "        cropped_img.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "\n",
    "for index, row in table_data.iterrows():\n",
    "    cell_id = row['cell_id']\n",
    "    img_path = os.path.join(CLASSES_PATH, row['bethesda_system'], f\"{row['cell_id']}.png\")\n",
    "    img_class = row['bethesda_system']\n",
    "\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    if image is not None:\n",
    "        q_img = quantize_image(image)\n",
    "        glcm = compute_glcm(q_img)\n",
    "        haralick_features = compute_haralick_features(glcm)\n",
    "\n",
    "        img_data.append ({\n",
    "            'cell_id': cell_id,\n",
    "            'image_path': img_path,\n",
    "            'contrast_1': haralick_features['contrast'][0],\n",
    "            'contrast_2': haralick_features['contrast'][1],\n",
    "            'contrast_4': haralick_features['contrast'][2],\n",
    "            'contrast_8': haralick_features['contrast'][3],\n",
    "            'contrast_16': haralick_features['contrast'][4],\n",
    "            'contrast_32': haralick_features['contrast'][5],\n",
    "            'homogeneity_1': haralick_features['homogeneity'][0],\n",
    "            'homogeneity_2': haralick_features['homogeneity'][1],\n",
    "            'homogeneity_4': haralick_features['homogeneity'][2],\n",
    "            'homogeneity_8': haralick_features['homogeneity'][3],\n",
    "            'homogeneity_16': haralick_features['homogeneity'][4],\n",
    "            'homogeneity_32': haralick_features['homogeneity'][5],\n",
    "            'entropy_1': haralick_features['entropy'][0],\n",
    "            'entropy_2': haralick_features['entropy'][1],\n",
    "            'entropy_4': haralick_features['entropy'][2],\n",
    "            'entropy_8': haralick_features['entropy'][3],\n",
    "            'entropy_16': haralick_features['entropy'][4],\n",
    "            'entropy_32': haralick_features['entropy'][5],\n",
    "            'img_class': img_class\n",
    "        })\n",
    "        \n",
    "dataset = pd.DataFrame(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.drop(columns=['cell_id', 'image_path', 'img_class'])\n",
    "labels = dataset['img_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels = np.array(['Negative' if label == 'Negative_for_intraepithelial_lesion' else 'Positive' for label in labels])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, binary_labels, test_size=0.2, stratify=binary_labels, random_state=49)\n",
    "\n",
    "# Step 1: Undersample the predominant class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=49, k_neighbors=5, sampling_strategy='not majority')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch for Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 'scale'],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "svc = SVC(class_weight='balanced', random_state=49)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Evaluate the Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_svm_classifier = SVC(**best_params, class_weight='balanced', random_state=49)\n",
    "binary_svm_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = binary_svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Binary SVC Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_matrix, classes=['Negative', 'Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the Binary SVM Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'binary_svm_classifier1.pkl'\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, model_filename)\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(binary_svm_classifier, file)\n",
    "\n",
    "# Load the model\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(\"Loaded Model Accuracy:\", accuracy_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=49)\n",
    "\n",
    "# Step 1: Undersample the predominant class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=49, k_neighbors=5, sampling_strategy='not majority')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomizedSearch for Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'C': loguniform(1e-3, 1e3),\n",
    "    'gamma': loguniform(1e-6, 1e-1),\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "svc = SVC(class_weight='balanced', random_state=49)\n",
    "\n",
    "# Instantiate the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=svc, param_distributions=param_distributions, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring='accuracy', random_state=49)\n",
    "\n",
    "# Time the randomized search\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Evaluate the Multiclass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_svm_classifier = SVC(**best_params, class_weight='balanced', random_state=49)\n",
    "multiclass_svm_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = multiclass_svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Multi-Class SVM Accuracy:\", accuracy)\n",
    "print(\"Multi-Class SVM Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_matrix, classes=['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative_for_intraepithelial_lesion', 'SCC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the Multiclass SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'multiclass_svm_classifier.pkl'\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, model_path)\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(multiclass_svm_classifier, file)\n",
    "\n",
    "# Load the model\n",
    "with open(model_filename, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(\"Loaded Model Accuracy:\", accuracy_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary EfficientNet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Treat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "class_name = 'binary_class'\n",
    "bin_data_dir = 'effnet_data_binary'\n",
    "\n",
    "df[class_name] = df['img_class'].apply(lambda x: 'Negative' if x == 'Negative_for_intraepithelial_lesion' else 'Positive')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[class_name], random_state=49)\n",
    "\n",
    "copy_train_test_imgs(train_df,test_df, class_name, bin_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = get_data_tranforms()\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(bin_data_dir, x),data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([label for _, label in image_datasets['train'].imgs])\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Criação de um WeightedRandomSampler\n",
    "class_sample_counts = np.array([len(np.where(train_labels == t)[0]) for t in np.unique(train_labels)])\n",
    "weights = 1. / class_sample_counts\n",
    "samples_weights = weights[train_labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "\n",
    "# Atualizando o DataLoader de treino para usar o WeightedRandomSampler\n",
    "train_loader = DataLoader(image_datasets['train'], batch_size=batch_size, sampler=sampler, num_workers=4)\n",
    "test_loader = dataloaders['test']\n",
    "dataloaders['train'] = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.4995 Acc: 0.5907\n",
      "test Loss: 0.8977 Acc: 0.4100\n",
      "\n",
      "Best val Acc: 0.410027\n"
     ]
    }
   ],
   "source": [
    "model_binary_efficientNet = train_model(model, dataloaders, criterion, optimizer, device, dataset_sizes, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.4100\n",
      "Precisão: 0.7921\n",
      "Recall: 0.4100\n",
      "F1-score: 0.3925\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxEAAAJwCAYAAAD2uOwtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABb3ElEQVR4nO3deZzNdf//8eeZ7cw+YzCGMJaxR8IVYyuZGmuUkshSomQpoi59K0tltFgiUSrLFaVslcoewpCQZCeaMGPs0xhm/fz+8HOucxocH9c45wyP+3U7t5t5f97nfF7n6Hu+XvN8vz8fi2EYhgAAAADgGnm5uwAAAAAAhQtNBAAAAABTaCIAAAAAmEITAQAAAMAUmggAAAAAptBEAAAAADCFJgIAAACAKTQRAAAAAEyhiQAAAABgCk0EgFve8OHDZbFYbug5LBaLhg8ffkPP4WrvvPOOKlSoIG9vb9WuXfuGnGPw4MEKCQlR9+7dderUKVWvXl2//vrrDTkXAODa0UQAcJnp06fLYrHIYrFo7dq1+Y4bhqEyZcrIYrGoTZs213WOUaNGaeHChf9jpYVDbm6upk2bpnvuuUcRERGyWq0qV66cnnjiCf3yyy839NxLly7Viy++qEaNGmnatGkaNWpUgZ8jPT1dkydP1siRI7Vjxw4VK1ZMwcHBqlWrVoGfCwBgDk0EAJfz9/fX7Nmz842vXr1ahw8fltVqve7Xvp4m4pVXXtH58+ev+5zucP78ebVp00ZPPvmkDMPQyy+/rMmTJ6tbt25KTEzUXXfdpcOHD9+w869cuVJeXl765JNP1K1bN7Vq1arAz+Hv76+dO3dq4MCB+uWXX3T48GFt2LBBXl78vy4AcDcfdxcA4NbTqlUrffXVV5owYYJ8fP77NTR79mzVrVtXJ06ccEkd586dU1BQkHx8fBzqKAyGDBmixYsXa9y4cXr++ecdjg0bNkzjxo27oedPTU1VQECA/Pz8btg5fHx8FB0dbfu5VKlSN+xcAABz+HUOAJd77LHHdPLkSS1btsw2lpWVpblz56pz586Xfc67776rhg0bqmjRogoICFDdunU1d+5chzkWi0Xnzp3TjBkzbMumevToIem/+x527typzp07q0iRImrcuLHDsUt69Ohhe/4/H872NWRmZmrgwIEqXry4QkJC9MADD1wxEThy5IiefPJJlShRQlarVTVq1NCnn37q7OPT4cOH9eGHH+q+++7L10BIkre3twYPHqzSpUvbxrZu3aqWLVsqNDRUwcHBat68uTZs2ODwvEvLzdatW6dBgwapePHiCgoK0oMPPqjjx4/b5lksFk2bNk3nzp2zfS7Tp0/XoUOHbH/+p39+dn///beef/55lStXTlarVZGRkbrvvvu0ZcsW25xVq1bp4YcfVtmyZWW1WlWmTBkNHDjwsqnRypUr1aRJEwUFBSk8PFzt2rXTrl27nH6WAIDrU7h+9QbgplCuXDnFxsbq888/V8uWLSVJP/zwg86ePatOnTppwoQJ+Z7z3nvv6YEHHlCXLl2UlZWlL774Qo888ogWLVqk1q1bS5L+85//6KmnntJdd92l3r17S5IqVqzo8DqPPPKIKlWqpFGjRskwjMvW9/TTTysuLs5hbPHixZo1a5YiIyOv+t6eeuopffbZZ+rcubMaNmyolStX2uqzd+zYMTVo0EAWi0X9+vVT8eLF9cMPP6hnz55KS0u7bHNwyQ8//KCcnBx17dr1qrVcsmPHDjVp0kShoaF68cUX5evrqw8//FD33HOPVq9erfr16zvM79+/v4oUKaJhw4bp0KFDGj9+vPr166c5c+ZIuvg5f/TRR/r555/18ccfS5IaNmx4TbVc8swzz2ju3Lnq16+fqlevrpMnT2rt2rXatWuX6tSpI0n68ssvdf78eT377LOKiIjQzz//rIkTJ+rw4cP66quvbK+1fPlytWzZUhUqVNDw4cN1/vx5TZw4UY0aNdKWLVtUrlw5U7UBAK6BAQAuMm3aNEOSsWnTJuP99983QkJCjIyMDMMwDOORRx4xmjVrZhiGYURHRxutW7d2eO6leZdkZWUZt99+u3Hvvfc6jAcFBRndu3fPd+5hw4YZkozHHnvsiseuZN++fUZYWJhx3333GTk5OVec9+uvvxqSjGeffdZhvHPnzoYkY9iwYbaxnj17GiVLljROnDjhMLdTp05GWFhYvvdrb+DAgYYkY+vWrVecY699+/aGn5+fceDAAdvY0aNHjZCQEKNp06a2sUt/P3FxcUZeXp7D+by9vY0zZ87Yxrp3724EBQU5nOfgwYOGJGPatGn5avjn+w8LCzP69u171brPnTuXbywhIcGwWCzGn3/+aRurXbu2ERkZaZw8edI2tm3bNsPLy8vo1q3bVc8BALg+LGcC4BYdO3bU+fPntWjRIv39999atGjRFZcySVJAQIDtz6dPn9bZs2fVpEkTh+Uv1+KZZ54xNf/cuXN68MEHVaRIEX3++efy9va+4tzvv/9ekjRgwACH8X+mCoZhaN68eWrbtq0Mw9CJEydsj/j4eJ09e/aq7ystLU2SFBIS4rT+3NxcLV26VO3bt1eFChVs4yVLllTnzp21du1a2+td0rt3b4flXU2aNFFubq7+/PNPp+e7VuHh4dq4caOOHj16xTmBgYG2P587d04nTpxQw4YNZRiGtm7dKklKTk7Wr7/+qh49eigiIsI2v1atWrrvvvtsfycAgILFciYAblG8eHHFxcVp9uzZysjIUG5urh5++OErzl+0aJHeeOMN/frrr8rMzLSNm72/Q/ny5U3N79Wrlw4cOKD169eraNGiV537559/ysvLK98SqipVqjj8fPz4cZ05c0YfffSRPvroo8u+Vmpq6hXPExoaKunivgJnjh8/royMjHw1SFK1atWUl5env/76SzVq1LCNly1b1mFekSJFJF1s3grK22+/re7du6tMmTKqW7euWrVqpW7dujk0OklJSXrttdf0zTff5Dv32bNnJcnW2Fzp/S1ZssS2gR4AUHBoIgC4TefOndWrVy+lpKSoZcuWCg8Pv+y8n376SQ888ICaNm2qDz74QCVLlpSvr6+mTZt22UvFXo19ouHMe++9p88//1yfffZZgd5MLS8vT5L0+OOPq3v37pedc7V7IVStWlWStH379htyk7crpS3GFfaQXHKlhi43NzffWMeOHdWkSRMtWLBAS5cu1TvvvKO33npL8+fPV8uWLZWbm6v77rtPp06d0ksvvaSqVasqKChIR44cUY8ePWyfIQDAPWgiALjNgw8+qKefflobNmywbdq9nHnz5snf319LlixxuIfEtGnT8s0tqDtP//TTTxo8eLCef/55denS5ZqeEx0drby8PB04cMDhN+N79uxxmHfpyk25ubn5NnBfi5YtW8rb21ufffaZ083VxYsXV2BgYL4aJGn37t3y8vJSmTJlTNdwOZcSizNnzjiMX2kZVMmSJfXss8/q2WefVWpqqurUqaM333xTLVu21Pbt27V3717NmDFD3bp1sz3H/opekmyXgL3S+ytWrBgpBADcAOyJAOA2wcHBmjx5soYPH662bdtecZ63t7csFovDb7QPHTp02ZvKBQUF5ftHrFnJycnq2LGjGjdurHfeeeean3fpSlP/vLrU+PHjHX729vZWhw4dNG/ePP3+++/5Xsf+cqqXU6ZMGfXq1UtLly7VxIkT8x3Py8vTmDFjdPjwYXl7e+v+++/X119/rUOHDtnmHDt2TLNnz1bjxo1ty6P+V6GhoSpWrJjWrFnjMP7BBx84/Jybm2tbjnRJZGSkSpUqZVuqdikNsU8/DMPQe++95/C8kiVLqnbt2poxY4bD3/vvv/+upUuX3pCb4AEASCIAuNmVlvPYa926tcaOHasWLVqoc+fOSk1N1aRJkxQTE6PffvvNYW7dunW1fPlyjR07VqVKlVL58uXzXcLUmQEDBuj48eN68cUX9cUXXzgcq1Wr1hWXGtWuXVuPPfaYPvjgA509e1YNGzbUihUrtH///nxzR48erR9//FH169dXr169VL16dZ06dUpbtmzR8uXLderUqavWOGbMGB04cEADBgzQ/Pnz1aZNGxUpUkRJSUn66quvtHv3bnXq1EmS9MYbb2jZsmVq3Lixnn32Wfn4+OjDDz9UZmam3n77bVOfjTNPPfWURo8eraeeekr16tXTmjVrtHfvXoc5f//9t0qXLq2HH35Yd9xxh4KDg7V8+XJt2rRJY8aMkXRxyVbFihU1ePBgHTlyRKGhoZo3b95l92W88847atmypWJjY9WzZ0/bJV7DwsKc3tcDAHCd3HlpKAC3FvtLvF7N5S7x+sknnxiVKlUyrFarUbVqVWPatGmXvTTr7t27jaZNmxoBAQGGJNvlXi/NPX78eL7z/fN17r77bkPSZR/2lym9nPPnzxsDBgwwihYtagQFBRlt27Y1/vrrr8s+99ixY0bfvn2NMmXKGL6+vkZUVJTRvHlz46OPPrrqOS7JyckxPv74Y6NJkyZGWFiY4evra0RHRxtPPPFEvsu/btmyxYiPjzeCg4ONwMBAo1mzZsb69esd5lzp7+fHH380JBk//vijbexyl3g1jIuX4u3Zs6cRFhZmhISEGB07djRSU1Md3n9mZqYxZMgQ44477jBCQkKMoKAg44477jA++OADh9fauXOnERcXZwQHBxvFihUzevXqZWzbtu2yl5Fdvny50ahRIyMgIMAIDQ012rZta+zcufOaPkcAgHkWw3CyUw4AAAAA7LAnAgAAAIApNBEAAAAATKGJAAAAAGAKTQQAAAAAU2giAAAAAJhCEwEAAADAFJoIAAAAAKbclHesXrzjuLtLAIAC9eDjI9xdAgAUqPNb33d3CVcUcGc/l53Lkz+HqyGJAAAAAGDKTZlEAAAAANfNwu/ZneETAgAAAGAKSQQAAABgz2JxdwUejyQCAAAAgCkkEQAAAIA99kQ4xScEAAAAwBSSCAAAAMAeeyKcIokAAAAAYApJBAAAAGCPPRFO8QkBAAAAMIUkAgAAALDHnginSCIAAAAAmEISAQAAANhjT4RTfEIAAAAATKGJAAAAAGAKy5kAAAAAe2ysdookAgAAAIApJBEAAACAPTZWO8UnBAAAAMAUkggAAADAHnsinCKJAAAAAGAKSQQAAABgjz0RTvEJAQAAADCFJAIAAACwx54Ip0giAAAAAJhCEgEAAADYY0+EU3xCAAAAAEwhiQAAAADskUQ4xScEAAAAwBSSCAAAAMCeF1dncoYkAgAAAIApJBEAAACAPfZEOMUnBAAAAMAUmggAAAAAprCcCQAAALBnYWO1MyQRAAAAQCFx5MgRPf744ypatKgCAgJUs2ZN/fLLL7bjhmHotddeU8mSJRUQEKC4uDjt27fP4TVOnTqlLl26KDQ0VOHh4erZs6fS09NN1UETAQAAANizeLnuYcLp06fVqFEj+fr66ocfftDOnTs1ZswYFSlSxDbn7bff1oQJEzRlyhRt3LhRQUFBio+P14ULF2xzunTpoh07dmjZsmVatGiR1qxZo969e5uqheVMAAAAQCHw1ltvqUyZMpo2bZptrHz58rY/G4ah8ePH65VXXlG7du0kSTNnzlSJEiW0cOFCderUSbt27dLixYu1adMm1atXT5I0ceJEtWrVSu+++65KlSp1TbWQRAAAAAD2LBaXPTIzM5WWlubwyMzMvGxZ33zzjerVq6dHHnlEkZGRuvPOOzV16lTb8YMHDyolJUVxcXG2sbCwMNWvX1+JiYmSpMTERIWHh9saCEmKi4uTl5eXNm7ceM0fEU0EAAAA4CYJCQkKCwtzeCQkJFx27h9//KHJkyerUqVKWrJkifr06aMBAwZoxowZkqSUlBRJUokSJRyeV6JECduxlJQURUZGOhz38fFRRESEbc61YDkTAAAAYM+FN5sbOnSoBg0a5DBmtVovOzcvL0/16tXTqFGjJEl33nmnfv/9d02ZMkXdu3e/4bXaI4kAAAAA3MRqtSo0NNThcaUmomTJkqpevbrDWLVq1ZSUlCRJioqKkiQdO3bMYc6xY8dsx6KiopSamupwPCcnR6dOnbLNuRY0EQAAAIA9F+6JMKNRo0bas2ePw9jevXsVHR0t6eIm66ioKK1YscJ2PC0tTRs3blRsbKwkKTY2VmfOnNHmzZttc1auXKm8vDzVr1//mmthORMAAABQCAwcOFANGzbUqFGj1LFjR/3888/66KOP9NFHH0mSLBaLnn/+eb3xxhuqVKmSypcvr1dffVWlSpVS+/btJV1MLlq0aKFevXppypQpys7OVr9+/dSpU6drvjKTRBMBAAAAOHLhnggz/vWvf2nBggUaOnSoRo4cqfLly2v8+PHq0qWLbc6LL76oc+fOqXfv3jpz5owaN26sxYsXy9/f3zZn1qxZ6tevn5o3by4vLy916NBBEyZMMFWLxTAMo8DemYdYvOO4u0sAgAL14OMj3F0CABSo81vfd3cJVxTQYqzLznV+8SDnkzwQSQQAAABgz+RehVuRZ2Y1AAAAADwWSQQAAABgz0P3RHgSPiEAAAAAppBEAAAAAPbYE+EUSQQAAAAAU0giAAAAAHvsiXCKTwgAAACAKTQRAAAAAExhORMAAABgj+VMTvEJAQAAADCFJAIAAACwxyVenSKJAAAAAGAKSQQAAABgjz0RTvEJAQAAADCFJAIAAACwx54Ip0giAAAAAJhCEgEAAADYY0+EU3xCAAAAAEwhiQAAAADssSfCKZIIAAAAAKaQRAAAAAB2LCQRTpFEAAAAADCFJAIAAACwQxLhHEkEAAAAAFNIIgAAAAB7BBFOkUQAAAAAMIUmAgAAAIApLGcCAAAA7LCx2jmSCAAAAACmkEQAAAAAdkginCOJAAAAAGAKSQQAAABghyTCOZIIAAAAAKaQRAAAAAB2SCKcI4kAAAAAYApJBAAAAGCPIMIpkggAAAAAppBEAAAAAHbYE+EcSQQAAAAAU0giAAAAADskEc6RRAAAAAAwhSQCAAAAsEMS4RxJBAAAAABTSCIAAAAAOyQRzpFEAAAAADCFJAIAAACwRxDhFEkEAAAAAFNoIgAAAACYwnImAAAAwA4bq50jiQAAAABgCkkEAAAAYIckwjmSCAAAAACmkEQAAAAAdkginCOJAAAAAGAKSQQAAABgjyDCKZIIAAAAAKaQRAAAAAB22BPhHEkEAAAAAFM8pon46aef9Pjjjys2NlZHjhyRJP3nP//R2rVr3VwZAAAAbiUWi8Vlj8LKI5qIefPmKT4+XgEBAdq6dasyMzMlSWfPntWoUaPcXB0AAAAAex7RRLzxxhuaMmWKpk6dKl9fX9t4o0aNtGXLFjdWBgAAgFsNSYRzHtFE7NmzR02bNs03HhYWpjNnzri+IAAAAABX5BFNRFRUlPbv359vfO3atapQoYIbKgIAAMCtiiTCOY9oInr16qXnnntOGzdulMVi0dGjRzVr1iwNHjxYffr0cXd5AAAAAOx4xH0i/v3vfysvL0/NmzdXRkaGmjZtKqvVqsGDB6t///7uLg8AAAC3ksIbELiMRzQRFotF//d//6chQ4Zo//79Sk9PV/Xq1RUcHOzu0gAAAAD8g0csZ/rss8+UkZEhPz8/Va9eXXfddRcNBAAAAOChPKKJGDhwoCIjI9W5c2d9//33ys3NdXdJAAAAuEWxsdo5j2gikpOT9cUXX8hisahjx44qWbKk+vbtq/Xr17u7NAAAAAD/4BFNhI+Pj9q0aaNZs2YpNTVV48aN06FDh9SsWTNVrFjR3eUBAADgFkIS4ZxHbKy2FxgYqPj4eJ0+fVp//vmndu3a5e6SAAAAANjxmCYiIyNDCxYs0KxZs7RixQqVKVNGjz32mObOnevu0gAAAHALKcwJgat4RBPRqVMnLVq0SIGBgerYsaNeffVVxcbGurssAAAAAJfhEXsivL299eWXXyo5OVnvv/8+DQQAAADcx+LChwnDhw/Pt6eiatWqtuMXLlxQ3759VbRoUQUHB6tDhw46duyYw2skJSWpdevWCgwMVGRkpIYMGaKcnBxzhchDkohZs2a5uwQAAADA49WoUUPLly+3/ezj899/zg8cOFDfffedvvrqK4WFhalfv3566KGHtG7dOklSbm6uWrduraioKK1fv17Jycnq1q2bfH19NWrUKFN1uK2JmDBhgnr37i1/f39NmDDhqnMHDBjgoqoAAABwq3PlnojMzExlZmY6jFmtVlmt1svO9/HxUVRUVL7xs2fP6pNPPtHs2bN17733SpKmTZumatWqacOGDWrQoIGWLl2qnTt3avny5SpRooRq166t119/XS+99JKGDx8uPz+/a67bbU3EuHHj1KVLF/n7+2vcuHFXnGexWGgiAAAAcFNKSEjQiBEjHMaGDRum4cOHX3b+vn37VKpUKfn7+ys2NlYJCQkqW7asNm/erOzsbMXFxdnmVq1aVWXLllViYqIaNGigxMRE1axZUyVKlLDNiY+PV58+fbRjxw7deeed11y325qIgwcPXvbPAAAAgDu5MokYOnSoBg0a5DB2pRSifv36mj59uqpUqaLk5GSNGDFCTZo00e+//66UlBT5+fkpPDzc4TklSpRQSkqKJCklJcWhgbh0/NIxMzxiY/XIkSOVkZGRb/z8+fMaOXKkGyoCAAAAbjyr1arQ0FCHx5WaiJYtW+qRRx5RrVq1FB8fr++//15nzpzRl19+6eKqPaSJGDFihNLT0/ONZ2Rk5It3AAAAgBupsNyxOjw8XJUrV9b+/fsVFRWlrKwsnTlzxmHOsWPHbHsooqKi8l2t6dLPl9tncTUecXUmwzAu+yFu27ZNERERbqgIt6pl8/6jbRtWK/XIn/L1s6p81Zpq27WPStxW1jYnOytTC6e/ry1rVygnJ1tVa9+lR3q/oNDw//63eup4ir76cIz2/b5FVv8A3dWspdo8/rS8vT3i/+QA3GJKFQ/TG8+10/2NaijQ31cH/jqhp4d/pi07k/LNnfB/ndTr4cYa8s5cvT97lW28dtXSeuO59qpbo6xycw0tXPGrXhozT+fOZ7nwnQCwl56ergMHDqhr166qW7eufH19tWLFCnXo0EGStGfPHiUlJdlunxAbG6s333xTqampioyMlCQtW7ZMoaGhql69uqlzu/VfNEWKFLF1YZUrV3ZoJHJzc5Wenq5nnnnGjRXiVrN/x1Y1afmQysZUVV5urhbN+kiTRwzU0AmfyeofIElaMG2idmxeryeGvK6AwCDNnTpOn771f3o+YbIkKS83Vx+9+aJCwiP0fMIUpZ0+oc8mvCkvbx+1ffxpd749ALeg8JAArZw+SKs37VP7fh/o+Ol0xZQtrtNp+ZcRP9Cslu6qWU5HU884jJcsHqbvpvTX3KVbNHD0lwoN8tc7Qzpo6siu6jzkExe9E8B1PPWO1YMHD1bbtm0VHR2to0ePatiwYfL29tZjjz2msLAw9ezZU4MGDVJERIRCQ0PVv39/xcbGqkGDBpKk+++/X9WrV1fXrl319ttvKyUlRa+88or69u17xSVUV+LWJmL8+PEyDENPPvmkRowYobCwMNsxPz8/lStXjhvPwaX6vDbW4ecu/V/W/z3RVn8d2KOYGrV1/ly6NqxYpG7PD1PlmnUlSZ37vaxRA7ro0J7fVa7K7dq97WelHD6kZ4ePv5hOlK+kVo89pW//M1ktH31SPr6+7nhrAG5RLzxxnw6nnNbTwz+zjf159GS+eaWKh2nsS4+o7bOTtGBiH4djLZvcruycXD2f8KUMw5Ak9X9zjn756mVVKFNMf/x14sa+CQCSpMOHD+uxxx7TyZMnVbx4cTVu3FgbNmxQ8eLFJV28+qmXl5c6dOigzMxMxcfH64MPPrA939vbW4sWLVKfPn0UGxuroKAgde/e/br2ILu1iejevbskqXz58mrYsKF8+ccVPMz5jHOSpMDgUEnSX3/sUW5OjirfUc82p0TpaBUpVkIH9+5QuSq369CeHSpVtoLD8qZqte/SVx++q5S/Dqp0hcqufRMAbmmt766p5et3adbbT6px3Uo6mnpGH335k6YtWG+bY7FY9Mkb3TRuxgrt+iP/FVqsfj7Kzs61NRCSdD7z4jKmhrUr0kTg5uOZQYS++OKLqx739/fXpEmTNGnSpCvOiY6O1vfff/8/1+IRG6vvvvtuWwNx4cIFpaWlOTyuJjMzM9/8rKzMqz4HuBZ5eXma/+kEla9aU6WiK0iS0k6flLePrwKDQhzmhoRH6O/TF3+zl3bmpELCI/Idv3QMAFyp/G3F1OuRJtqfdFwPPDtJU79aqzEvPqwubevb5rzwxH3Kyc3TpM9XXfY1Vv28RyWKhmpgt+by9fFWeEiA3hjQTpIUVTzsss8BcHPziCYiIyND/fr1U2RkpIKCglSkSBGHx9UkJCQoLCzM4fHl1PdcVDluZnOnjlVK0h/qMYgrhAEovLy8LPp1918a9v632rbnsD6dv07TFqxXr4cbS5LurFZGfR+7R72HfXbF19j1R4p6vfYfDejaXKcSx+rQ8lE6dOSkUk6kycjLc9VbAVymsFydyZ084lIxQ4YM0Y8//qjJkyera9eumjRpko4cOaIPP/xQo0ePvupzL3eDjlUHrp5eAM7MnTpWO35ZrwFvvK/wYpG28dAiRZWbk62Mc387pBF/nzmlkCJFL84JL6qkfbscXu/vM6dsxwDAlVJOpOVborT7YIraN68tSWp0Z0VFRgRr7/f/XRPt4+Ot0YMeUr8uzVS19TBJ0pzFv2jO4l8UGRGic+czZRjSgMfv1cHDJKzArcgjmohvv/1WM2fO1D333KMnnnhCTZo0UUxMjKKjozVr1ix16dLlis+1Wq35dpP7+bGcCdfHMAzN+3icftu4Rv1GTlTREqUcjpepUEXePj7a+9tm1Y69R5J07EiSTp84pvKVa0iSylWpoaXzZurvM6cVEn4xSduzbZP8A4MUVaacK98OACjx1z9UOTrSYaxS2UglJV/85cbs7zZp5cY9Dse//aCvZn/3s2Z+vSHf66We+luS1K1dA13IytaKDbtvUOUAPJlHNBGnTp1ShQoX15yHhobq1KmLX2yNGzdWnz59rvZUoEB99dEYbflpuZ4amiD/gECl/f99Dv6BwfKzWhUQFKwGzdto4bSJCgoOlX9goOZ+PF7lqtyuclVulyRVveMuRZUup88mvK4HuvZR2plT+m72VDVu8ZB8fP3c+fYA3IImfrZSP05/QUOevF/zlm3Rv2qU05MdGqnf659Lkk6dPadTZ885PCc7J1fHTqRp35+ptrFnHm2qDdv+UHpGlpo3qKpRz7fXqxO/1tn08y59P4ArFOZlRq7iEU1EhQoVdPDgQZUtW1ZVq1bVl19+qbvuukvffvutwsPD3V0ebiHrliyUJE18tb/DeOd+L6v+va0kSQ8+0V8Wi0WfvvN/ysn+783mLvHy9lbvl9/Wlx+9q3FDn5Gff4DuuqeFWj3W02XvAwAu2bwzSY++MFUj+z+gl3u31KEjJzXknXn64odfTL1Ovduj9cozrRUc6Kc9h46p35uf6/PvNt2gqgF4Oothf702Nxk3bpy8vb01YMAALV++XG3btpVhGMrOztbYsWP13HPPmXq9xTuO36BKAcA9HnycDf4Abi7nt77v7hKuKGbwDy471/53W7rsXAXJI5KIgQMH2v4cFxen3bt3a/PmzYqJiVGtWrXcWBkAAACAf/KIJuKfoqOjFR0d7e4yAAAAcAtiT4RzHtFETJgw4bLjFotF/v7+iomJUdOmTeXt7e3iygAAAAD8k0c0EePGjdPx48eVkZFhu7nc6dOnFRgYqODgYKWmpqpChQr68ccfVaZMGTdXCwAAgJsZQYRzHnHH6lGjRulf//qX9u3bp5MnT+rkyZPau3ev6tevr/fee09JSUmKiopy2DsBAAAAwD08Iol45ZVXNG/ePFWsWNE2FhMTo3fffVcdOnTQH3/8obffflsdOnRwY5UAAAC4FbAnwjmPSCKSk5OVk5OTbzwnJ0cpKSmSpFKlSunvv/92dWkAAAAA/sEjmohmzZrp6aef1tatW21jW7duVZ8+fXTvvfdKkrZv367y5cu7q0QAAADcIiwW1z0KK49oIj755BNFRESobt26slqtslqtqlevniIiIvTJJ59IkoKDgzVmzBg3VwoAAADAI/ZEREVFadmyZdq9e7f27t0rSapSpYqqVKlim9OsWTN3lQcAAIBbiJdXIY4IXMQjmohLKlSoIIvFoooVK8rHx6NKAwAAAPD/ecRypoyMDPXs2VOBgYGqUaOGkpKSJEn9+/fX6NGj3VwdAAAAbiXsiXDOI5qIoUOHatu2bVq1apX8/f1t43FxcZozZ44bKwMAAADwTx6xZmjhwoWaM2eOGjRo4HBd3ho1aujAgQNurAwAAAC3Gu4T4ZxHJBHHjx9XZGRkvvFz587xlwgAAAB4GI9oIurVq6fvvvvO9vOlxuHjjz9WbGysu8oCAAAAcBkesZxp1KhRatmypXbu3KmcnBy999572rlzp9avX6/Vq1e7uzwAAADcQlgI45xHJBGNGzfWr7/+qpycHNWsWVNLly5VZGSkEhMTVbduXXeXBwAAAMCORyQRklSxYkVNnTrV3WUAAADgFseeXOfc2kR4eXk5/UuyWCzKyclxUUUAAAAAnHFrE7FgwYIrHktMTNSECROUl5fnwooAAABwqyOJcM6tTUS7du3yje3Zs0f//ve/9e2336pLly4aOXKkGyoDAAAAcCUesbFako4ePapevXqpZs2aysnJ0a+//qoZM2YoOjra3aUBAADgFmKxuO5RWLm9iTh79qxeeuklxcTEaMeOHVqxYoW+/fZb3X777e4uDQAAAMBluHU509tvv6233npLUVFR+vzzzy+7vAkAAABwJfZEOOfWJuLf//63AgICFBMToxkzZmjGjBmXnTd//nwXVwYAAADgStzaRHTr1o1ODwAAAB6Ff54659YmYvr06e48PQAAAIDr4DF3rAYAAAA8AStlnHP71ZkAAAAAFC4kEQAAAIAdggjnSCIAAAAAmEISAQAAANhhT4RzJBEAAAAATCGJAAAAAOwQRDhHEgEAAADAFJoIAAAAAKawnAkAAACww8Zq50giAAAAAJhCEgEAAADYIYhwjiQCAAAAgCkkEQAAAIAd9kQ4RxIBAAAAwBSSCAAAAMAOQYRzJBEAAAAATCGJAAAAAOywJ8I5kggAAAAAppBEAAAAAHYIIpwjiQAAAABgCkkEAAAAYIc9Ec6RRAAAAAAwhSQCAAAAsEMS4RxJBAAAAABTSCIAAAAAOwQRzpFEAAAAADCFJgIAAACAKSxnAgAAAOywsdo5kggAAAAAppBEAAAAAHYIIpwjiQAAAABgCkkEAAAAYIc9Ec6RRAAAAAAwhSQCAAAAsEMQ4RxJBAAAAABTSCIAAAAAO15EEU6RRAAAAAAwhSYCAAAAsGOxuO5xvUaPHi2LxaLnn3/eNnbhwgX17dtXRYsWVXBwsDp06KBjx445PC8pKUmtW7dWYGCgIiMjNWTIEOXk5Jg+P00EAAAAUIhs2rRJH374oWrVquUwPnDgQH377bf66quvtHr1ah09elQPPfSQ7Xhubq5at26trKwsrV+/XjNmzND06dP12muvma6BJgIAAACwY7FYXPYwKz09XV26dNHUqVNVpEgR2/jZs2f1ySefaOzYsbr33ntVt25dTZs2TevXr9eGDRskSUuXLtXOnTv12WefqXbt2mrZsqVef/11TZo0SVlZWabqoIkAAAAA3CQzM1NpaWkOj8zMzCvO79u3r1q3bq24uDiH8c2bNys7O9thvGrVqipbtqwSExMlSYmJiapZs6ZKlChhmxMfH6+0tDTt2LHDVN00EQAAAIAdL4vrHgkJCQoLC3N4JCQkXLauL774Qlu2bLns8ZSUFPn5+Sk8PNxhvESJEkpJSbHNsW8gLh2/dMwMLvEKAAAAuMnQoUM1aNAghzGr1Zpv3l9//aXnnntOy5Ytk7+/v6vKuyKSCAAAAMCOK/dEWK1WhYaGOjwu10Rs3rxZqampqlOnjnx8fOTj46PVq1drwoQJ8vHxUYkSJZSVlaUzZ844PO/YsWOKioqSJEVFReW7WtOlny/NuVY0EQAAAICHa968ubZv365ff/3V9qhXr566dOli+7Ovr69WrFhhe86ePXuUlJSk2NhYSVJsbKy2b9+u1NRU25xly5YpNDRU1atXN1UPy5kAAAAAO554w+qQkBDdfvvtDmNBQUEqWrSobbxnz54aNGiQIiIiFBoaqv79+ys2NlYNGjSQJN1///2qXr26unbtqrffflspKSl65ZVX1Ldv38umH1dDEwEAAADcBMaNGycvLy916NBBmZmZio+P1wcffGA77u3trUWLFqlPnz6KjY1VUFCQunfvrpEjR5o+l8UwDKMgi/cEi3ccd3cJAFCgHnx8hLtLAIACdX7r++4u4Ypaf/izy8713dN3uexcBYkkAgAAALBjkQeuZ/IwbKwGAAAAYApJBAAAAGDHiyDCKZIIAAAAAKaQRAAAAAB2LJ54jVcPQxIBAAAAwBSSCAAAAMAOQYRzJBEAAAAATCGJAAAAAOx4EUU4RRIBAAAAwBSSCAAAAMAOQYRzJBEAAAAATCGJAAAAAOxwnwjnSCIAAAAAmEISAQAAANghiHCOJAIAAACAKSQRAAAAgB3uE+HcdTcRx48f1549eyRJVapUUfHixQusKAAAAACey/RypnPnzunJJ59UqVKl1LRpUzVt2lSlSpVSz549lZGRcSNqBAAAAOBBTDcRgwYN0urVq/XNN9/ozJkzOnPmjL7++mutXr1aL7zwwo2oEQAAAHAZiwsfhZXp5Uzz5s3T3Llzdc8999jGWrVqpYCAAHXs2FGTJ08uyPoAAAAAeBjTTURGRoZKlCiRbzwyMpLlTAAAACj0uNmcc6aXM8XGxmrYsGG6cOGCbez8+fMaMWKEYmNjC7Q4AAAAAJ7HdBIxfvx4tWjRQqVLl9Ydd9whSdq2bZv8/f21ZMmSAi8QAAAAcCUvgginTDcRNWvW1L59+zRr1izt3r1bkvTYY4+pS5cuCggIKPACAQAAAHgWU01Edna2qlatqkWLFqlXr143qiYAAADAbdgT4ZypPRG+vr4OeyEAAAAA3HpMb6zu27ev3nrrLeXk5NyIegAAAAC3slhc9yisTO+J2LRpk1asWKGlS5eqZs2aCgoKcjg+f/78AisOAAAAgOcx3USEh4erQ4cON6IWAAAAwO3YE+Gc6SZi2rRpN6IOAAAAAIWE6SYCAAAAuJlxnwjnrqmJqFOnjlasWKEiRYrozjvvvGrEs2XLlgIrDgAAAIDnuaYmol27drJarZKk9u3b38h6AAAAALdiT4Rz19REDBs27LJ/BgAAAHDrMX2fCEk6c+aMPv74Yw0dOlSnTp2SdHEZ05EjRwq0OAAAAMDVLC58FFamN1b/9ttviouLU1hYmA4dOqRevXopIiJC8+fPV1JSkmbOnHkj6gQAAADgIUwnEYMGDVKPHj20b98++fv728ZbtWqlNWvWFGhxAAAAgKt5WSwuexRWppuITZs26emnn843fttttyklJaVAigIAAADguUw3EVarVWlpafnG9+7dq+LFixdIUQAAAAA8l+km4oEHHtDIkSOVnZ0t6eIlsJKSkvTSSy+pQ4cOBV4gAAAA4EoWi+sehZXpJmLMmDFKT09XZGSkzp8/r7vvvlsxMTEKCQnRm2++eSNqBAAAAOBBTF+dKSwsTMuWLdPatWv122+/KT09XXXq1FFcXNyNqA8AAABwKW4255zpJuKSxo0bq3HjxgVZCwAAAIBC4JqaiAkTJlzzCw4YMOC6iwEAAADcjSDCuWtqIsaNG+fw8/Hjx5WRkaHw8HBJF+9gHRgYqMjISJoIAAAA4CZ3TRurDx48aHu8+eabql27tnbt2qVTp07p1KlT2rVrl+rUqaPXX3/9RtcLAAAA3FDcbM4501dnevXVVzVx4kRVqVLFNlalShWNGzdOr7zySoEWBwAAAMDzmN5YnZycrJycnHzjubm5OnbsWIEUBQAAALhLIQ4IXMZ0EtG8eXM9/fTT2rJli21s8+bN6tOnD5d5BQAAAG4BppuITz/9VFFRUapXr56sVqusVqvuuusulShRQh9//PGNqBEAAABwGYvF4rJHYWV6OVPx4sX1/fffa+/evdq9e7ckqWrVqqpcuXKBFwcAAADA81z3zeYqV67ssY3DPVWKu7sEAChQ700e4u4SAOCWYXqpzi3oupqIw4cP65tvvlFSUpKysrIcjo0dO7ZACgMAAADgmUw3EStWrNADDzygChUqaPfu3br99tt16NAhGYahOnXq3IgaAQAAAJcpzHsVXMV0WjN06FANHjxY27dvl7+/v+bNm6e//vpLd999tx555JEbUSMAAAAAD2K6idi1a5e6desmSfLx8dH58+cVHByskSNH6q233irwAgEAAABX8rK47lFYmW4igoKCbPsgSpYsqQMHDtiOnThxouAqAwAAAOCRTO+JaNCggdauXatq1aqpVatWeuGFF7R9+3bNnz9fDRo0uBE1AgAAAPAgppuIsWPHKj09XZI0YsQIpaena86cOapUqRJXZgIAAEChV5iXGbmK6SaiQoUKtj8HBQVpypQpBVoQAAAAAM923TebAwAAAG5GXOLVuWtqIooUKXLNH+apU6f+p4IAAAAAeLZraiLGjx9v+/PJkyf1xhtvKD4+XrGxsZKkxMRELVmyRK+++uoNKRIAAABwFfZEOGcxDMMw84QOHTqoWbNm6tevn8P4+++/r+XLl2vhwoUFWd91uZDj7goAoGDN/OVPd5cAAAWqd4Nod5dwRUMW7XHZud5pU8Vl5ypIpu8TsWTJErVo0SLfeIsWLbR8+fICKQoAAABwF4vFdY/CynQTUbRoUX399df5xr/++msVLVq0QIoCAAAA4LlMX51pxIgReuqpp7Rq1SrVr19fkrRx40YtXrxYU6dOLfACAQAAAFfyKswRgYuYbiJ69OihatWqacKECZo/f74kqVq1alq7dq2tqQAAAABw8zLVRGRnZ+vpp5/Wq6++qlmzZt2omgAAAAC3Mb3e/xZk6jPy9fXVvHnzblQtAAAAAAoB041W+/btPeIyrgAAAMCNwNWZnDO9J6JSpUoaOXKk1q1bp7p16yooKMjh+IABAwqsOAAAAACex3QS8cknnyg8PFybN2/WRx99pHHjxtke9ne2BgAAAAojL4vFZQ8zJk+erFq1aik0NFShoaGKjY3VDz/8YDt+4cIF9e3bV0WLFlVwcLA6dOigY8eOObxGUlKSWrdurcDAQEVGRmrIkCHKyTF/p2bTScTBgwdNnwQAAADA/6Z06dIaPXq0KlWqJMMwNGPGDLVr105bt25VjRo1NHDgQH333Xf66quvFBYWpn79+umhhx7SunXrJEm5ublq3bq1oqKitH79eiUnJ6tbt27y9fXVqFGjTNViMQzDuJ43kZWVpYMHD6pixYry8THdi9xQF8w3UwDg0Wb+8qe7SwCAAtW7QbS7S7ii15bsc9m5RsZX+p+eHxERoXfeeUcPP/ywihcvrtmzZ+vhhx+WJO3evVvVqlVTYmKiGjRooB9++EFt2rTR0aNHVaJECUnSlClT9NJLL+n48ePy8/O75vOaXs6UkZGhnj17KjAwUDVq1FBSUpIkqX///ho9erTZlwMAAABuWZmZmUpLS3N4ZGZmOn1ebm6uvvjiC507d06xsbHavHmzsrOzFRcXZ5tTtWpVlS1bVomJiZKkxMRE1axZ09ZASFJ8fLzS0tK0Y8cOU3WbbiKGDh2qbdu2adWqVfL397eNx8XFac6cOWZfDgAAAPAoXhbXPRISEhQWFubwSEhIuGJt27dvV3BwsKxWq5555hktWLBA1atXV0pKivz8/BQeHu4wv0SJEkpJSZEkpaSkODQQl45fOmaG6XVICxcu1Jw5c9SgQQNZ7DaD1KhRQwcOHDD7cgAAAMAta+jQoRo0aJDDmNVqveL8KlWq6Ndff9XZs2c1d+5cde/eXatXr77RZeZjuok4fvy4IiMj842fO3fOoakAAAAAcHVWq/WqTcM/+fn5KSYmRpJUt25dbdq0Se+9954effRRZWVl6cyZMw5pxLFjxxQVFSVJioqK0s8//+zwepeu3nRpzrUyvZypXr16+u6772w/X2ocPv74Y8XGxpp9OQAAAMCjeOolXi8nLy9PmZmZqlu3rnx9fbVixQrbsT179igpKcn2b/TY2Fht375dqamptjnLli1TaGioqlevbuq815xE/P7777r99tuVkJCgFi1aaOfOncrOztZ7772nnTt3av369W6JUgAAAIBbwdChQ9WyZUuVLVtWf//9t2bPnq1Vq1ZpyZIlCgsLU8+ePTVo0CBFREQoNDRU/fv3V2xsrBo0aCBJuv/++1W9enV17dpVb7/9tlJSUvTKK6+ob9++ptIQyUQSUatWLdWvX187d+7UunXrlJOTo1q1amnp0qWKjIxUYmKi6tata+6TAAAAADyMxeK6hxmpqanq1q2bqlSpoubNm2vTpk1asmSJ7rvvPknSuHHj1KZNG3Xo0EFNmzZVVFSU5s+fb3u+t7e3Fi1aJG9vb8XGxurxxx9Xt27dNHLkSPOf0bXeJ+Knn37StGnTNHfuXOXl5alDhw7q2bOnmjZtavqkNxr3iQBws+E+EQBuNp58n4jXl+932blejYtx2bkK0jUnEU2aNNGnn36q5ORkTZw4UYcOHdI999yjypUr66233jJ9WSgAAADAE7nyEq+FlemN1UFBQXriiSe0evVq7d27V4888ogmTZqksmXL6oEHHrgRNQIAAADwIKYv8WovJiZGL7/8sqKjozV06FCHqzYBAAAAhZFFhTgicJHrbiLWrFmjTz/9VPPmzZOXl5c6duyonj17FmRtAAAAADyQqSbi6NGjmj59uqZPn679+/erYcOGmjBhgjp27KigoKAbVSMAAADgMoV5r4KrXHMT0bJlSy1fvlzFihVTt27d9OSTT6pKlSo3sjYAAAAAHuiamwhfX1/NnTtXbdq0kbe3942sCQAAAHAbkgjnrrmJ+Oabb25kHQAAAAAKif/p6kwAAADAzcZi9lbStyDT94kAAAAAcGsjiQAAAADssCfCOZIIAAAAAKaQRAAAAAB22BLhHEkEAAAAAFNoIgAAAACYwnImAAAAwI4X65mcIokAAAAAYApJBAAAAGCHS7w6RxIBAAAAwBSSCAAAAMAOWyKcI4kAAAAAYApJBAAAAGDHS0QRzpBEAAAAADCFJAIAAACww54I50giAAAAAJhCEgEAAADY4T4RzpFEAAAAADCFJAIAAACw48WmCKdIIgAAAACYQhIBAAAA2CGIcI4kAgAAAIApJBEAAACAHfZEOEcSAQAAAMAUkggAAADADkGEcyQRAAAAAEyhiQAAAABgCsuZAAAAADv8lt05PiMAAAAAppBEAAAAAHYs7Kx2iiQCAAAAgCkkEQAAAIAdcgjnSCIAAAAAmEISAQAAANjxYk+EUyQRAAAAAEwhiQAAAADskEM4RxIBAAAAwBSSCAAAAMAOWyKcI4kAAAAAYApJBAAAAGCHO1Y7RxIBAAAAwBSSCAAAAMAOv2V3js8IAAAAgCkkEQAAAIAd9kQ4RxIBAAAAwBSaCAAAAACmsJwJAAAAsMNiJudIIgAAAACYQhIBAAAA2GFjtXMkEQAAAABMIYkAAAAA7PBbduf4jAAAAACYQhIBAAAA2GFPhHMkEQAAAABMIYkAAAAA7JBDOEcSAQAAAMAUkggAAADADlsinCOJAAAAAGAKSQQAAABgx4tdEU6RRAAAAAAwhSQCAAAAsMOeCOdIIgAAAACYQhIBAAAA2LGwJ8IpkggAAAAAppBEAAAAAHbYE+EcSQQAAABQCCQkJOhf//qXQkJCFBkZqfbt22vPnj0Ocy5cuKC+ffuqaNGiCg4OVocOHXTs2DGHOUlJSWrdurUCAwMVGRmpIUOGKCcnx1QtNBEAAABAIbB69Wr17dtXGzZs0LJly5Sdna37779f586ds80ZOHCgvv32W3311VdavXq1jh49qoceesh2PDc3V61bt1ZWVpbWr1+vGTNmaPr06XrttddM1WIxDMMosHfmIS6Ya6QAwOPN/OVPd5cAAAWqd4Nod5dwRYt3HHfZuZrFhCozM9NhzGq1ymq1On3u8ePHFRkZqdWrV6tp06Y6e/asihcvrtmzZ+vhhx+WJO3evVvVqlVTYmKiGjRooB9++EFt2rTR0aNHVaJECUnSlClT9NJLL+n48ePy8/O7prpJIgAAAAA3SUhIUFhYmMMjISHhmp579uxZSVJERIQkafPmzcrOzlZcXJxtTtWqVVW2bFklJiZKkhITE1WzZk1bAyFJ8fHxSktL044dO665bjZWAwAAAHZcubF66NChGjRokMPYtaQQeXl5ev7559WoUSPdfvvtkqSUlBT5+fkpPDzcYW6JEiWUkpJim2PfQFw6funYtaKJAAAAANzkWpcu/VPfvn31+++/a+3atTegKuc8ZjnTTz/9pMcff1yxsbE6cuSIJOk///mP2z4YAAAA3JosFtc9rke/fv20aNEi/fjjjypdurRtPCoqSllZWTpz5ozD/GPHjikqKso2559Xa7r086U518Ijmoh58+YpPj5eAQEB2rp1q21zydmzZzVq1Cg3VwcAAAC4n2EY6tevnxYsWKCVK1eqfPnyDsfr1q0rX19frVixwja2Z88eJSUlKTY2VpIUGxur7du3KzU11TZn2bJlCg0NVfXq1a+5Fo9oIt544w1NmTJFU6dOla+vr228UaNG2rJlixsrAwAAwK3G4sL/mdG3b1999tlnmj17tkJCQpSSkqKUlBSdP39ekhQWFqaePXtq0KBB+vHHH7V582Y98cQTio2NVYMGDSRJ999/v6pXr66uXbtq27ZtWrJkiV555RX17dvX1LIqj9gTsWfPHjVt2jTfeFhYWL44BgAAALgVTZ48WZJ0zz33OIxPmzZNPXr0kCSNGzdOXl5e6tChgzIzMxUfH68PPvjANtfb21uLFi1Snz59FBsbq6CgIHXv3l0jR440VYtHNBFRUVHav3+/ypUr5zC+du1aVahQwT1FAQAA4Jbk5cKrM5lxLbd38/f316RJkzRp0qQrzomOjtb333//P9XiEcuZevXqpeeee04bN26UxWLR0aNHNWvWLA0ePFh9+vRxd3kAAAAA7HhEEvHvf/9beXl5at68uTIyMtS0aVNZrVYNHjxY/fv3d3d5AAAAuIWY3atwK7IY15KLuEhWVpb279+v9PR0Va9eXcHBwdf1OhdyCrgwAHCzmb/86e4SAKBA9W4Q7e4Srmjl7pMuO9e9VYu67FwFySOSiM8++0wPPfSQAgMDTV1aCgAAAChorrxjdWHlEXsiBg4cqMjISHXu3Fnff/+9cnNz3V0SAAAAgCvwiCYiOTlZX3zxhSwWizp27KiSJUuqb9++Wr9+vbtLAwAAwC3GU+8T4Uk8oonw8fFRmzZtNGvWLKWmpmrcuHE6dOiQmjVrpooVK7q7PAAAAAB2PGJPhL3AwEDFx8fr9OnT+vPPP7Vr1y53lwQAAIBbiKfeJ8KTeEQSIUkZGRmaNWuWWrVqpdtuu03jx4/Xgw8+qB07dri7NAAAAAB2PCKJ6NSpkxYtWqTAwEB17NhRr776qmJjY91dFgAAAIDL8IgmwtvbW19++aXi4+Pl7e3t7nIAAABwCyvMG55dxSOaiFmzZrm7BAAAAADXyG1NxIQJE9S7d2/5+/trwoQJV507YMAAF1UFAACAWx03m3POYhiG4Y4Tly9fXr/88ouKFi2q8uXLX3GexWLRH3/8Yeq1L+T8r9UB/7X5l02a/ukn2rXzdx0/flzjJkzSvc3jbMcNw9AH70/Q/Llf6e+/01T7zjr6v9eGKzq6nPuKxk1n5i9/ursEFFIbv/1c+zav06nkv+Tj66dSlaqracenFFGyjG3OnITBOrz7N4fn1WrWWvf1eM72c8ofe/TTV5/o2KF9kiyKqlBFTR99SpFluRQ7rk/vBtHuLuGK1u477bJzNa5UxGXnKkhuSyIOHjx42T8Dnub8+QxVqVJF7R/qoEHP9ct3fNonU/X5rP/o9VGjddttpTVp4nvq07unFnzzvaxWqxsqBoD/Orxnu2o3f0BR5SsrLy9Xa+dO09x3huqJhKnytQbY5tW8u6UaPdTd9rOP3fdX1oXzmvfuy6p4Z6yad+uvvNxcrV8wU/PefVm9x86St49HrI4GCgxBhHMecYnXkSNHKiMjI9/4+fPnNXLkSDdUBPxX4yZ3q99zA9U87r58xwzD0Kz/zFSvp/uo2b1xqlylqt5IeFvHU1O1csVyN1QLAI46DB6l25vcr2KlyymybEW1eGqw/j6ZqmMH9znM87X6Kyg8wvawBgTZjp1K/ksXzv2thg91U0TJMipWupxi23dVxtnTSjt5zNVvCYAH8IgmYsSIEUpPT883npGRoREjRrihIuDaHDl8WCdOHFf9Bg1tYyEhIapZ6w79tm2rGysDgMvLPH9OkuQfHOIwvitxpSb1fVjTX+6ln778RNmZF2zHIqJKyz84VL+vWazcnGxlZ2Xq9zWLFVGqrMKKRbm0fsAVvCwWlz0KK4/IHw3DkOUyH+K2bdsUERFx1edmZmYqMzPT8fW8rSwjgUucOHFcklS0WFGH8aJFi+rEiRPuKAkArsjIy9OqWVNUqlINFSv93/2I1Ro0U2ixEgoKL6oTf/2hNV9+olMph9VuwDBJkl9AoB4d+o6+fm+ENnw9W5IUHlVKDw9OkBeXZgduSW5NIooUKaKIiAhZLBZVrlxZERERtkdYWJjuu+8+dezY8aqvkZCQoLCwMIfHO28luOgdAABQeKyY+b5OHDmkNs++7DBeq1lrlatZT8XLlFe1hs3VsvcQ7d+8TmeOHZUkZWdlasknY1WqUnV1fu09dXplnIrdVk7zx76i7KzMy50KKNQsLnwUVm5NIsaPHy/DMPTkk09qxIgRCgsLsx3z8/NTuXLlnN65eujQoRo0aJDDmOFNCgHXKFasuCTp5ImTKl480jZ+8uRJVala1V1lAUA+K2a+rwPbNqjTy2MUElH8qnNLVrz4/XUm9ajCS5TS7sSVSjtxTJ1ffU8Wr4u/f2zdZ6je7/OQDmxZr6oNmt3w+gF4Frc2Ed27X7wKRPny5dWwYUP5+vqafg2rNf/SJS7xCle5rXRpFStWXBs3JqpqtWqSpPT0dG3/bZseefQxN1cHABeXDK/8zyTt37xOHYe+q7DiJZ0+J/XPi5dWDwq7uKQ4OytTFouXw8XzLRYvWSwWuelK8cCNVZgjAhdxWxORlpam0NBQSdKdd96p8+fP6/z585ede2ke4A4Z584pKSnJ9vORw4e1e9cuhYWFqWSpUurStZumfjhZ0WWjdVvpi5d4LR4Z6XAvCQBwlxUzJ2r3hh/V7rkR8vMP0LkzpyRJfoFB8vWz6syxo9q1YaUq1LpL/sGhOv7XQa2aPUWlq9RU8bIVJEnRNepozZypWjFzou68r72MvDz9/N0ceXl7q0y1O9z59gC4idtuNuft7a3k5GRFRkbKy8vrshurL224zs3NNfXaJBEoSJt+3qinnuiWb/yBdg/q9VGjbTebm/fVl/r77zTdWaeuXn51mMqVu/JNFAGzuNkcrteY7vdfdjz+qcG6vcn9SjuZqh8+fEsnDh9SdtYFhUQUV0zdRmrwQGeHy7we+n2zEhd+ppNHDsli8VJkdEU16vCESsVUc9VbwU3Gk282t/HAWZedq37FMOeTPJDbmojVq1erUaNG8vHx0erVq6869+677zb12jQRAG42NBEAbjY0ERcV1ibCbcuZ7BsDs00CAAAAcKMU4ts3uIxH3Gxu8eLFWrt2re3nSZMmqXbt2urcubNOnz7txsoAAAAA/JNHNBFDhgxRWlqaJGn79u0aNGiQWrVqpYMHD+a7fCsAAABwI3GfCOc84o7VBw8eVPXq1SVJ8+bNU9u2bTVq1Cht2bJFrVq1cnN1AAAAAOx5RBLh5+enjIwMSdLy5ct1//0XryQRERFhSygAAAAAlyCKcMojkojGjRtr0KBBatSokX7++WfNmTNHkrR3716VLl3azdUBAAAAsOcRScT7778vHx8fzZ07V5MnT9Ztt90mSfrhhx/UokULN1cHAAAAwJ7b7hNxI3GfCAA3G+4TAeBm48n3ifjloOuW09crH+qycxUkj1jOJEm5ublauHChdu3aJUmqUaOGHnjgAXl7e7u5MgAAAAD2PKKJ2L9/v1q1aqUjR46oSpUqkqSEhASVKVNG3333nSpWrOjmCgEAAHCr4GZzznnEnogBAwaoYsWK+uuvv7RlyxZt2bJFSUlJKl++vAYMGODu8gAAAADY8YgkYvXq1dqwYYMiIiJsY0WLFtXo0aPVqFEjN1YGAACAWw1BhHMekURYrVb9/fff+cbT09Pl5+fnhooAAAAAXIlHNBFt2rRR7969tXHjRhmGIcMwtGHDBj3zzDN64IEH3F0eAAAAbiXcbM4pj2giJkyYoJiYGDVs2FD+/v7y9/dXo0aNFBMTo/fee8/d5QEAAACw49Y9EXl5eXrnnXf0zTffKCsrS+3bt1f37t1lsVhUrVo1xcTEuLM8AAAA3IIshTkicBG3NhFvvvmmhg8frri4OAUEBOj7779XWFiYPv30U3eWBQAAAOAq3LqcaebMmfrggw+0ZMkSLVy4UN9++61mzZqlvLw8d5YFAACAW5jF4rpHYeXWJiIpKUmtWrWy/RwXFyeLxaKjR4+6sSoAAAAAV+PW5Uw5OTny9/d3GPP19VV2drabKgIAAMCtrhAHBC7j1ibCMAz16NFDVqvVNnbhwgU988wzCgoKso3Nnz/fHeUBAAAAuAy3NhHdu3fPN/b444+7oRIAAADg/yOKcMqtTcS0adPceXoAAAAA18GtTQQAAADgabhPhHMeccdqAAAAAIUHTQQAAAAAU1jOBAAAANgpzDeBcxWSCAAAAACmkEQAAAAAdgginCOJAAAAAGAKSQQAAABgjyjCKZIIAAAAAKaQRAAAAAB2uNmccyQRAAAAAEwhiQAAAADscJ8I50giAAAAAJhCEgEAAADYIYhwjiQCAAAAgCkkEQAAAIA9oginSCIAAAAAmEISAQAAANjhPhHOkUQAAAAAMIUkAgAAALDDfSKcI4kAAAAAYApNBAAAAABTWM4EAAAA2GE1k3MkEQAAAABMIYkAAAAA7BFFOEUSAQAAAMAUmggAAADAjsWF/zNjzZo1atu2rUqVKiWLxaKFCxc6HDcMQ6+99ppKliypgIAAxcXFad++fQ5zTp06pS5duig0NFTh4eHq2bOn0tPTTX9GNBEAAABAIXDu3DndcccdmjRp0mWPv/3225owYYKmTJmijRs3KigoSPHx8bpw4YJtTpcuXbRjxw4tW7ZMixYt0po1a9S7d2/TtVgMwzCu+514qAs57q4AAArWzF/+dHcJAFCgejeIdncJV7Q/9bzLzhUTGXBdz7NYLFqwYIHat28v6WIKUapUKb3wwgsaPHiwJOns2bMqUaKEpk+frk6dOmnXrl2qXr26Nm3apHr16kmSFi9erFatWunw4cMqVarUNZ+fJAIAAABwk8zMTKWlpTk8MjMzTb/OwYMHlZKSori4ONtYWFiY6tevr8TERElSYmKiwsPDbQ2EJMXFxcnLy0sbN240dT6aCAAAAMCOxYWPhIQEhYWFOTwSEhJM15ySkiJJKlGihMN4iRIlbMdSUlIUGRnpcNzHx0cRERG2OdeKS7wCAAAAbjJ06FANGjTIYcxqtbqpmmtHEwEAAADYc+F9IqxWa4E0DVFRUZKkY8eOqWTJkrbxY8eOqXbt2rY5qampDs/LycnRqVOnbM+/VixnAgAAAAq58uXLKyoqSitWrLCNpaWlaePGjYqNjZUkxcbG6syZM9q8ebNtzsqVK5WXl6f69eubOh9JBAAAAGDH7P0bXCU9PV379++3/Xzw4EH9+uuvioiIUNmyZfX888/rjTfeUKVKlVS+fHm9+uqrKlWqlO0KTtWqVVOLFi3Uq1cvTZkyRdnZ2erXr586depk6spMEk0EAAAAUCj88ssvatasme3nS3spunfvrunTp+vFF1/UuXPn1Lt3b505c0aNGzfW4sWL5e/vb3vOrFmz1K9fPzVv3lxeXl7q0KGDJkyYYLoW7hMBAIUA94kAcLPx5PtEHDxxwfmkAlK+mL/zSR6IPREAAAAATGE5EwAAAGDHM3dEeBaSCAAAAACmkEQAAAAA9oginCKJAAAAAGAKTQQAAAAAU1jOBAAAANjx1JvNeRKSCAAAAACmkEQAAAAAdiwEEU6RRAAAAAAwhSQCAAAAsEMQ4RxJBAAAAABTSCIAAAAAO+yJcI4kAgAAAIApJBEAAACAA6IIZ0giAAAAAJhCEgEAAADYYU+EcyQRAAAAAEwhiQAAAADsEEQ4RxIBAAAAwBSSCAAAAMAOeyKcI4kAAAAAYApJBAAAAGDHwq4Ip0giAAAAAJhCEwEAAADAFJYzAQAAAPZYzeQUSQQAAAAAU0giAAAAADsEEc6RRAAAAAAwhSQCAAAAsMPN5pwjiQAAAABgCkkEAAAAYIebzTlHEgEAAADAFJIIAAAAwB5BhFMkEQAAAABMIYkAAAAA7BBEOEcSAQAAAMAUkggAAADADveJcI4kAgAAAIApJBEAAACAHe4T4RxJBAAAAABTSCIAAAAAO+yJcI4kAgAAAIApNBEAAAAATKGJAAAAAGAKTQQAAAAAU9hYDQAAANhhY7VzJBEAAAAATCGJAAAAAOxwsznnSCIAAAAAmEISAQAAANhhT4RzJBEAAAAATCGJAAAAAOwQRDhHEgEAAADAFJIIAAAAwB5RhFMkEQAAAABMIYkAAAAA7HCfCOdIIgAAAACYQhIBAAAA2OE+Ec6RRAAAAAAwhSQCAAAAsEMQ4RxJBAAAAABTSCIAAAAAe0QRTpFEAAAAADCFJgIAAACAKSxnAgAAAOxwsznnSCIAAAAAmEISAQAAANjhZnPOkUQAAAAAMMViGIbh7iKAwigzM1MJCQkaOnSorFaru8sBgP8Z32sArhVNBHCd0tLSFBYWprNnzyo0NNTd5QDA/4zvNQDXiuVMAAAAAEyhiQAAAABgCk0EAAAAAFNoIoDrZLVaNWzYMDYfArhp8L0G4FqxsRoAAACAKSQRAAAAAEyhiQAAAABgCk0EAAAAAFNoIgAXKVeunMaPH+/uMgAgn1WrVslisejMmTNXncf3GIBLaCJwU+jRo4csFotGjx7tML5w4UJZLBaX1jJ9+nSFh4fnG9+0aZN69+7t0loA3FwufddZLBb5+fkpJiZGI0eOVE5Ozv/0ug0bNlRycrLCwsIk8T0GwDmaCNw0/P399dZbb+n06dPuLuWyihcvrsDAQHeXAaCQa9GihZKTk7Vv3z698MILGj58uN55553/6TX9/PwUFRXl9JcufI8BuIQmAjeNuLg4RUVFKSEh4Ypz1q5dqyZNmiggIEBlypTRgAEDdO7cOdvx5ORktW7dWgEBASpfvrxmz56dL74fO3asatasqaCgIJUpU0bPPvus0tPTJV1cEvDEE0/o7Nmztt8WDh8+XJLjMoDOnTvr0UcfdagtOztbxYoV08yZMyVJeXl5SkhIUPny5RUQEKA77rhDc+fOLYBPCkBhZrVaFRUVpejoaPXp00dxcXH65ptvdPr0aXXr1k1FihRRYGCgWrZsqX379tme9+eff6pt27YqUqSIgoKCVKNGDX3//feSHJcz8T0G4FrQROCm4e3trVGjRmnixIk6fPhwvuMHDhxQixYt1KFDB/3222+aM2eO1q5dq379+tnmdOvWTUePHtWqVas0b948ffTRR0pNTXV4HS8vL02YMEE7duzQjBkztHLlSr344ouSLi4JGD9+vEJDQ5WcnKzk5GQNHjw4Xy1dunTRt99+a2s+JGnJkiXKyMjQgw8+KElKSEjQzJkzNWXKFO3YsUMDBw7U448/rtWrVxfI5wXg5hAQEKCsrCz16NFDv/zyi7755hslJibKMAy1atVK2dnZkqS+ffsqMzNTa9as0fbt2/XWW28pODg43+vxPQbgmhjATaB79+5Gu3btDMMwjAYNGhhPPvmkYRiGsWDBAuPSf+Y9e/Y0evfu7fC8n376yfDy8jLOnz9v7Nq1y5BkbNq0yXZ83759hiRj3LhxVzz3V199ZRQtWtT287Rp04ywsLB886Kjo22vk52dbRQrVsyYOXOm7fhjjz1mPProo4ZhGMaFCxeMwMBAY/369Q6v0bNnT+Oxxx67+ocB4KZl/12Xl5dnLFu2zLBarUb79u0NSca6detsc0+cOGEEBAQYX375pWEYhlGzZk1j+PDhl33dH3/80ZBknD592jAMvscAOOfj1g4GuAHeeust3Xvvvfl+c7Zt2zb99ttvmjVrlm3MMAzl5eXp4MGD2rt3r3x8fFSnTh3b8ZiYGBUpUsThdZYvX66EhATt3r1baWlpysnJ0YULF5SRkXHNa4V9fHzUsWNHzZo1S127dtW5c+f09ddf64svvpAk7d+/XxkZGbrvvvscnpeVlaU777zT1OcB4OayaNEiBQcHKzs7W3l5eercubMeeughLVq0SPXr17fNK1q0qKpUqaJdu3ZJkgYMGKA+ffpo6dKliouLU4cOHVSrVq3rroPvMeDWRhOBm07Tpk0VHx+voUOHqkePHrbx9PR0Pf300xowYEC+55QtW1Z79+51+tqHDh1SmzZt1KdPH7355puKiIjQ2rVr1bNnT2VlZZnacNilSxfdfffdSk1N1bJlyxQQEKAWLVrYapWk7777TrfddpvD86xW6zWfA8DNp1mzZpo8ebL8/PxUqlQp+fj46JtvvnH6vKeeekrx8fH67rvvtHTpUiUkJGjMmDHq37//ddfC9xhw66KJwE1p9OjRql27tqpUqWIbq1Onjnbu3KmYmJjLPqdKlSrKycnR1q1bVbduXUkXf5Nmf7WnzZs3Ky8vT2PGjJGX18UtRV9++aXD6/j5+Sk3N9dpjQ0bNlSZMmU0Z84c/fDDD3rkkUfk6+srSapevbqsVquSkpJ09913m3vzAG5qQUFB+b7HqlWrppycHG3cuFENGzaUJJ08eVJ79uxR9erVbfPKlCmjZ555Rs8884yGDh2qqVOnXraJ4HsMgDM0Ebgp1axZU126dNGECRNsYy+99JIaNGigfv366amnnlJQUJB27typZcuW6f3331fVqlUVFxen3r17a/LkyfL19dULL7yggIAA22UPY2JilJ2drYkTJ6pt27Zat26dpkyZ4nDucuXKKT09XStWrNAdd9yhwMDAKyYUnTt31pQpU7R37179+OOPtvGQkBANHjxYAwcOVF5enho3bqyzZ89q3bp1Cg0NVffu3W/ApwagsKpUqZLatWunXr166cMPP1RISIj+/e9/67bbblO7du0kSc8//7xatmypypUr6/Tp0/rxxx9VrVq1y74e32MAnHL3pgygINhvNrzk4MGDhp+fn2H/n/nPP/9s3HfffUZwcLARFBRk1KpVy3jzzTdtx48ePWq0bNnSsFqtRnR0tDF79mwjMjLSmDJlim3O2LFjjZIlSxoBAQFGfHy8MXPmTIcNiYZhGM8884xRtGhRQ5IxbNgwwzAcNyResnPnTkOSER0dbeTl5Tkcy8vLM8aPH29UqVLF8PX1NYoXL27Ex8cbq1ev/t8+LACF1uW+6y45deqU0bVrVyMsLMz2/bR3717b8X79+hkVK1Y0rFarUbx4caNr167GiRMnDMPIv7HaMPgeA3B1FsMwDDf2MIBHO3z4sMqUKaPly5erefPm7i4HAADAI9BEAHZWrlyp9PR01axZU8nJyXrxxRd15MgR7d2717bOFwAA4FbHngjATnZ2tl5++WX98ccfCgkJUcOGDTVr1iwaCAAAADskEQAAAABM8XJ3AQAAAAAKF5oIAAAAAKbQRAAAAAAwhSYCAAAAgCk0EQAAAABMoYkAgEKmR48eat++ve3ne+65R88//7zb6gEA3HpoIgCggPTo0UMWi0UWi0V+fn6KiYnRyJEjlZOTc0PPO3/+fL3++uu2n8uVK6fx48ff0HMCAG5t3GwOAApQixYtNG3aNGVmZur7779X37595evrq6FDhzrMy8rKkp+fX4GcMyIiokBeBwCAa0USAQAFyGq1KioqStHR0erTp4/i4uL0zTff2JYgvfnmmypVqpSqVKkiSfrrr7/UsWNHhYeHKyIiQu3atdOhQ4dsr5ebm6tBgwYpPDxcRYsW1Ysvvqh/3iPUfjnTPffcoz///FMDBw60pSKXzJs3TzVq1JDValW5cuU0ZsyYG/55AABuTjQRAHADBQQEKCsrS5K0YsUK7dmzR8uWLdOiRYuUnZ2t+Ph4hYSE6KefftK6desUHBysFi1a2J4zZswYTZ8+XZ9++qnWrl2rU6dOacGCBVc83/z581W6dGmNHDlSycnJSk5OliRt3rxZHTt2VKdOnbR9+3YNHz5cr776qqZPn37DPwMAwM2H5UwAcAMYhqEVK1ZoyZIl6t+/v44fP66goCB9/PHHtmVMn332mfLy8vTxxx/bEoNp06YpPDxcq1at0v3336/x48dr6NCheuihhyRJU6ZM0ZIlS6543oiICHl7eyskJERRUVG28bFjx6p58+Z69dVXJUmVK1fWzp079c4776hHjx436FMAANysSCIAoAAtWrRIwcHB8vf3V8uWLfXoo49q+PDhkqSaNWs67IPYtm2b9u/fr5CQEAUHBys4OFgRERG6cOGCDhw4oLNnzyo5OVn169e3PcfHx0f16tUzXdeuXbvUqFEjh7FGjRpp3759ys3Nvb43CwC4ZZFEAEABatasmSZPniw/Pz+VKlVKPj7//ZoNCgpymJuenq66detq1qxZ+V6nePHiN7xWAACuF00EABSgoKAgxcTEXNPcOnXqaM6cOYqMjFRoaOhl55QsWVIbN25U06ZNJUk5OTnavHmz6tSpc8XX9fPzy5cuVKtWTevWrXMYW7dunSpXrixvb+9rqhcAgEtYzgQAbtKlSxcVK1ZM7dq1008//aSDBw9q1apVGjBggA4fPixJeu655zR69GgtXLhQu3fv1rPPPqszZ85c9XXLlSunNWvW6MiRIzpx4oQk6YUXXtCKFSv0+uuva+/evZoxY4bef/99DR48+Ea/TQDATYgmAgDcJDAwUGvWrFHZsmX10EMPqVq1aurZs6cuXLhgSyZeeOEFde3aVd27d1dsbKxCQkL04IMPXvV1R44cqUOHDqlixYq2ZVF16tTRl19+qS+++EK33367XnvtNY0cOZJN1QCA62Ix/nnBcQAAAAC4CpIIAAAAAKbQRAAAAAAwhSYCAAAAgCk0EQAAAABMoYkAAAAAYApNBAAAAABTaCIAAAAAmEITAQAAAMAUmggAAAAAptBEAAAAADCFJgIAAACAKf8PaLp7IsdEvL8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.95      0.24      0.38       849\n",
      "    Positive       0.28      0.96      0.44       268\n",
      "\n",
      "    accuracy                           0.41      1117\n",
      "   macro avg       0.62      0.60      0.41      1117\n",
      "weighted avg       0.79      0.41      0.39      1117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_binary_efficientNet = model_binary_efficientNet.to(torch.device('cuda:0'))\n",
    "\n",
    "# Avalia o modelo no conjunto de teste\n",
    "labels, preds = evaluate_model(model_binary_efficientNet, dataloaders, device)\n",
    "\n",
    "# Calcula acurácia, precisão, recall e F1-score\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Imprime as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Precisão: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Converte a matriz de confusão para um DataFrame para melhor visualização\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação detalhado\n",
    "report = classification_report(labels, preds, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "path = 'models/efficientNet_binary1.pth'\n",
    "torch.save(model_binary_efficientNet.to(torch.device('cpu')), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass EfficientNet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split and Treat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "class_name = 'img_class'\n",
    "multi_data_dir = 'effnet_data_multiclass'\n",
    "\n",
    "df = df[df[class_name] != 'Negative_for_intraepithelial_lesion']\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[class_name], random_state=49)\n",
    "\n",
    "copy_train_test_imgs(train_df,test_df, class_name, multi_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = get_data_tranforms()\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(multi_data_dir, x),data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([label for _, label in image_datasets['train'].imgs])\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Criação de um WeightedRandomSampler\n",
    "class_sample_counts = np.array([len(np.where(train_labels == t)[0]) for t in np.unique(train_labels)])\n",
    "weights = 1. / class_sample_counts\n",
    "samples_weights = weights[train_labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "\n",
    "# Atualizando o DataLoader de treino para usar o WeightedRandomSampler\n",
    "train_loader = DataLoader(image_datasets['train'], batch_size=batch_size, sampler=sampler, num_workers=4)\n",
    "test_loader = dataloaders['test']\n",
    "dataloaders['train'] = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiclass_efficientNet = train_model(model, dataloaders, criterion, optimizer, device,  dataset_sizes, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia o modelo no conjunto de teste\n",
    "model_multiclass_efficientNet = model_multiclass_efficientNet.to(torch.device('cuda:0'))\n",
    "labels, preds = evaluate_model(model_multiclass_efficientNet, dataloaders, device)\n",
    "\n",
    "# Calcula acurácia, precisão, recall e F1-score\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Imprime as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Precisão: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Converte a matriz de confusão para um DataFrame para melhor visualização\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação detalhado\n",
    "report = classification_report(labels, preds, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "path = 'models/efficientNet_muticlass.pth'\n",
    "torch.save(model_multiclass_efficientNet.to(torch.device('cpu')), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
